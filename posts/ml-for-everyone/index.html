<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=theme-color content="#494f5c"><meta name=msapplication-TileColor content="#494f5c"><meta itemprop=name content="Machine Learning For the Masses (and How to Retrain GPT-2)"><meta itemprop=description content="This assumes the reader is on the Windows operating system, but much of the information is relevant to any other OS.
The initial aim of this post was solely a step-by-step guide to retrain GPT-2 using a custom dataset, but I will also ponder on the future of AI and machine learning (not on its progress per se but on how we will interact with it, in the future).
Thanks to Ng Wai Foong for this useful guide on training GPT-2 that helped me a lot."><meta itemprop=datePublished content="2019-09-22T00:00:00+00:00"><meta itemprop=dateModified content="2019-09-22T00:00:00+00:00"><meta itemprop=wordCount content="1478"><meta itemprop=keywords content><meta property="og:title" content="Machine Learning For the Masses (and How to Retrain GPT-2)"><meta property="og:description" content="This assumes the reader is on the Windows operating system, but much of the information is relevant to any other OS.
The initial aim of this post was solely a step-by-step guide to retrain GPT-2 using a custom dataset, but I will also ponder on the future of AI and machine learning (not on its progress per se but on how we will interact with it, in the future).
Thanks to Ng Wai Foong for this useful guide on training GPT-2 that helped me a lot."><meta property="og:type" content="article"><meta property="og:url" content="https://cyberchris.xyz/posts/ml-for-everyone/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-09-22T00:00:00+00:00"><meta property="article:modified_time" content="2019-09-22T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Machine Learning For the Masses (and How to Retrain GPT-2)"><meta name=twitter:description content="This assumes the reader is on the Windows operating system, but much of the information is relevant to any other OS.
The initial aim of this post was solely a step-by-step guide to retrain GPT-2 using a custom dataset, but I will also ponder on the future of AI and machine learning (not on its progress per se but on how we will interact with it, in the future).
Thanks to Ng Wai Foong for this useful guide on training GPT-2 that helped me a lot."><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color><link rel="shortcut icon" href=/favicon.ico><title>Machine Learning For the Masses (and How to Retrain GPT-2)</title><link rel=stylesheet href=https://cyberchris.xyz/css/style.min.ca05074214be80afcdb2729d1a0e905a3e5c2d492b3fa899786ac429dc46f61f.css integrity="sha256-ygUHQhS+gK/NsnKdGg6QWj5cLUkrP6iZeGrEKdxG9h8=" crossorigin=anonymous><script defer data-domain=cyberchris.xyz src=http://analytics.cyberchris.xyz/js/plausible.js></script></head><body id=page><header id=site-header class="animated slideInUp"><div class="hdr-wrapper section-inner"><div class=hdr-left><div class=site-branding><a href=https://cyberchris.xyz>Chris Tomy</a></div><nav class="site-nav hide-in-mobile"><a href=https://cyberchris.xyz/posts/>Posts</a>
<a href=https://cyberchris.xyz/showcase/>Showcase</a>
<a href=https://cv.cyberchris.xyz/>CV</a>
<a href=https://cyberchris.xyz/about/>About</a></nav></div><div class="hdr-right hdr-icons"><span class="hdr-social hide-in-mobile"><a href=https://github.com/cyber-chris target=_blank rel="noopener me" title=Github><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://www.linkedin.com/in/chris-tomy/ target=_blank rel="noopener me" title=Linkedin><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></span><button id=menu-btn class=hdr-btn title=Menu><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button></div></div></header><div id=mobile-menu class="animated fast"><ul><li><a href=https://cyberchris.xyz/posts/>Posts</a></li><li><a href=https://cyberchris.xyz/showcase/>Showcase</a></li><li><a href=https://cv.cyberchris.xyz/>CV</a></li><li><a href=https://cyberchris.xyz/about/>About</a></li></ul></div><main class="site-main section-inner animated fadeIn faster"><article class=thin><header class=post-header><div class=post-meta><span>Sep 22, 2019</span></div><h1>Machine Learning For the Masses (and How to Retrain GPT-2)</h1></header><div class=content><p>This assumes the reader is on the Windows operating system, but much of the information is relevant to any other OS.</p><p>The initial aim of this post was solely a step-by-step guide to retrain GPT-2 using a custom dataset, but I will also ponder on the future of AI and machine learning (not on its progress per se but on how <em>we</em> will interact with it, in the future).</p><p>Thanks to Ng Wai Foong for <a href=https://medium.com/@ngwaifoong92/beginners-guide-to-retrain-gpt-2-117m-to-generate-custom-text-content-8bb5363d8b7f>this</a> useful guide on training GPT-2 that helped me a lot.</p><h1 id=gpt-2>GPT-2<a href=#gpt-2 class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><blockquote><p><em>the model too risky to be released</em></p></blockquote><p>We&rsquo;ll be looking at how to retrain the well-known GPT-2 model on our own dataset of choice. The aim is for the model to learn the patterns of any text that you provide it.
This requires zero technical knowledge or any background in ML, although some basic git and python experience might be useful to debug any problems you may have.</p><h2 id=your-dataset>Your Dataset<a href=#your-dataset class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h2><p>Before we begin it&rsquo;s best to discuss what text is best to provide it. If you&rsquo;ve already decided what you want to train it on, you can just collect that text and paste it into a text file.
I would also recommend separating the examples with <code>&lt;|endoftext|></code>, like below:</p><blockquote><p><em>(Excerpt from my dataset text file)</em></p></blockquote><pre tabindex=0><code>And all my days are trances,
And all my nightly dreams
Are where thy grey eye glances,
And where thy footstep gleams-
In what ethereal dances,
By what eternal streams.

&lt;|endoftext|&gt;

The skies they were ashen and sober;
The leaves they were crisped and sere-
The leaves they were withering and sere;
It was night in the lonesome October
Of my most immemorial year;
It was hard by the dim lake of Auber,
In the misty mid region of Weir-
It was down by the dank tarn of Auber,
In the ghoul-haunted woodland of Weir.

...
</code></pre><p>I trained GPT-2 on poems written by Edgar Allen Poe. I was curious to see if it could replicate his style (which is fairly distinct).
I would recommend training it on something a little simpler and in the modern English language. Unless you have a particularly powerful computer, it will take a while for it to learn the structure and semantics of your text.
However, the model we will use is already pretrained on text found on the internet, so it will pick up conventional English quickly.</p><h1 id=getting-gpt-2>Getting GPT-2<a href=#getting-gpt-2 class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>We&rsquo;re going to be getting a <a href=https://github.com/nshepperd/gpt-2>&lsquo;fork&rsquo; of the original</a> GPT-2 from @nshepperd (since the original GPT-2 is considered archived, with no updates expected):</p><ol><li>Follow the <a href=https://github.com/nshepperd/gpt-2>link</a>.</li><li>Press the green &lsquo;Clone or download&rsquo; button and select &lsquo;Download ZIP&rsquo;.</li><li>Extract the contents of the ZIP to any location, and open up the folder.</li><li>Since, I was training it on a windows machine (which makes it inconvenient to modify the PATH variable), I instead copied the files <em>encode.py</em> and <em>train.py</em> into the <em>src</em> folder.</li></ol><h1 id=python-setup>Python Setup<a href=#python-setup class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>First check if you already have python:</p><ol><li>Open up the command line, cmd or powershell.</li><li>Enter the command: <code>python --version</code></li><li>If you get an error message then you should install it as explained below, else skip to the next heading.</li></ol><p>It&rsquo;s pretty easy to get python just install it from the <a href=https://www.python.org/downloads/>website</a> and make sure you select <em>add python and/or pip to the (system) path</em> (or alternative phrasing) during the installation process so you can run it from the command line.</p><h2 id=python-modules>Python Modules<a href=#python-modules class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h2><p>We now need to satisfy any dependencies for the code. The best way would be to install it using the requirements.txt file amongst the files you downloaded.</p><ol><li>Find the <em>requirements.txt</em> file amongst the downloaded files.</li><li>Assuming you used the standard windows 10 file manager, hold <em>SHIFT</em> and press <em>RIGHT-CLICK</em> - not on a file, but anywhere amongst the empty space below the list of files.</li><li>Select <em>Open Powershell Window</em>.</li><li>Enter the command: <code>pip install -r ./requirements.txt</code></li></ol><p>It&rsquo;s possible you recieved an error message. If so, read the output and try to resolve any missing dependencies (using a Google search).
If it still doesn&rsquo;t work, you could just manually install the four required modules. Enter these commands one at a time:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>pip install fire
</span></span><span class=line><span class=cl>pip install regex
</span></span><span class=line><span class=cl>pip install requests
</span></span><span class=line><span class=cl>pip install tqdm
</span></span></code></pre></div><p>in the command line. This is less preferred in case the requirements change, but in that case you could just look at what&rsquo;s in the requirements.txt file and install the relevant modules.</p><h1 id=final-setup>Final Setup<a href=#final-setup class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>Nearly about to start training just a few more steps&mldr;</p><ol><li>Copy your text file with the dataset inside into the <em>src</em> folder.</li><li>Open up powershell inside this folder like you did before.</li><li>Enter the command: <code>python encode.py dataset.txt dataset.npz</code> (this encodes the dataset so the model can read it)
&mldr;where dataset.txt is your dataset text file. It can be called anything, just make sure to modify the above command to match the name of the file.</li></ol><h2 id=getting-the-117m-model>Getting the 117M model<a href=#getting-the-117m-model class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h2><ol><li>Find the file download_model.py amongst the installed files.</li><li>Open up powershell in this folder.</li><li>Enter command: <code>python download_model.py 117M</code></li></ol><h1 id=training>Training<a href=#training class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>Finally, it&rsquo;s time to train the model. It will take a fair bit of resources and slow down performance if you are doing anything else while training. It&rsquo;s best to just leave it to train and not use the computer.</p><p>Open up powershell in the folder that contains your encoded dataset and enter the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>python train.py --dataset dataset.npz --sample_every <span class=m>50</span> --sample_num <span class=m>2</span>
</span></span></code></pre></div><p>You can change &lsquo;2&rsquo; to any number of samples you want to generate as you train it. Generating samples while you train allows you to see the progress of the model.
Press <em>CTRL+C</em> to stop the training. Technically, it <em>pauses</em>, since you can just run the command again and it will pick up where it left off (as long as you didn&rsquo;t change any of the files).</p><p>That&rsquo;s about it, you now have the ability to generate as many samples as you&rsquo;d like while training. There are some more steps that you could go through once you have your perfect model that would allow you to generate more samples <em>without</em> training. However, it is unlikely you will reach a perfect model, so for the purposes of this post what we have covered is sufficient. I also find it more interesting to generate and view samples as it trains, allowing me to see its progress with each iteration.</p><h1 id=for-the-masses>For the masses?<a href=#for-the-masses class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h1><p>It is clear that, similar to the widespread proliferation of information - and the number of people that have access to it - the internet will (and mostly has) enable(d) billions of people to utilise machine learning technologies. However, as we have just worked through, the process is a bit fiddly and not amazingly effective.</p><p>Hmm&mldr; just like a lot of early tech that we take now take for granted.</p><p>It seems to me that the next step of ML/AI technology is not some breakthrough that will allow Skynet-like AI roaming around, but instead for there to be a set of tools that completely abstract much of the &lsquo;fiddly&rsquo; setup and implementation that is currently required to generate samples.</p><p>If such tools existed (which would be used in a similar fashion to current alternatives like TensorFlow or Keras), opportunities would arise for specialist &rsquo;trainers&rsquo; who would be able to fine tune parameters to produce optimal samples.</p><p>The ML community would be split into, firstly, the mathematicians focusing on the matrix crunching that goes behind training models, and secondly, trainers who are effective at the art of finetuning parameters, which is a different skill.</p><p>It could also open the possibility of companies selling pre-trained models suited to do a particular task, with paying customers using the model to generate samples to their heart&rsquo;s content (possibly even hiring a trainer to do it for them if they want better results).</p><p>As a result, copyright law would likely append an unusual provision - one may not use a sample outside the uses stated in the user licence agreement provided by the company which sold the model. This would tackle the problem of people perhaps selling novels generated with the model, when the company actually only sold it to customers for personal use/entertainment.</p><p>It sparks up the (now tiresome to many) question of data ownership.
If I sell you a model trained on Stephen King&rsquo;s novels, and you generate a 600-page sample that reads like one of Stephen King&rsquo;s works, who owns the sample? Do you (the consumer), the company or Stephen King himself own it?</p><h2 id=closing>Closing<a href=#closing class=anchor aria-hidden=true><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 015 5 5 5 0 01-5 5h-3m-6 0H6a5 5 0 01-5-5 5 5 0 015-5h3"/><line x1="8" y1="12" x2="16" y2="12"/></svg></a></h2><p>These are my opinions/predictions on the future of (our interaction with) ML/AI. I believe things will be simplified before we advance. Taking a step back, before another two forward, if you will. As a first year CS student, I do not know precisely how feasible my statements are, because I am not an expert (yet), but I plan to return this topic in the future and see how accurate I was.</p></div><hr class=post-end><footer class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>1478 Words</p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>2019-09-22 00:00 +0000</p></footer></article><div class="post-nav thin"><a class=next-post href=https://cyberchris.xyz/posts/vim-guide/><span class=post-nav-label><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"/><polyline points="12 19 5 12 12 5"/></svg>&nbsp;Newer</span><br><span>The (Ultimate) Vim(rc) Guide, with plugins</span></a>
<a class=prev-post href=https://cyberchris.xyz/posts/rss-added/><span class=post-nav-label>Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"/><polyline points="12 5 19 12 12 19"/></svg></span><br><span>RSS Support added</span></a></div><div id=comments class=thin></div></main><footer id=site-footer class="section-inner thin animated fadeIn faster"><p>&copy; 2022 <a href=https://cyberchris.xyz>Chris Tomy</a> &#183; <a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank rel=noopener>CC BY-NC 4.0</a></p><p>Made with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> &#183; Theme <a href=https://github.com/Track3/hermit target=_blank rel=noopener>Hermit</a> &#183; <a href=https://cyberchris.xyz/posts/index.xml target=_blank title=rss><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></p></footer><script src=https://cyberchris.xyz/js/bundle.min.b9f909b41bc63c7720c4f081b68b869f9aa7333026213a6555a6a84002a05a71.js integrity="sha256-ufkJtBvGPHcgxPCBtouGn5qnMzAmITplVaaoQAKgWnE=" crossorigin=anonymous></script></body></html>